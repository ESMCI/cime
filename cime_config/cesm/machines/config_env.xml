<?xml version="1.0"?>
<config_env>
  <!-- titan not ported yet -->
  <machine mach="titan">
    <module_system>module</module_system>
	<init_path lang="perl"></init_path>
  </machine>
  <machine mach="edison">
     <module_system>module</module_system>
	    <!-- get the module init path by language -->
        <init_path lang="perl">/opt/modules/default/init/perl</init_path>
        <init_path lang="python">/opt/modules/default/init/python</init_path>
	    <!-- get the module command  path by language -->
	    <cmd_path lang="perl">/opt/modules/default/bin/modulecmd perl</cmd_path>

	  <!-- blocks contain modules.  Currently, blocks without XML attributes 
		   are always loaded.  Blocks with attributes are only loaded if the 
           attribute matches.  
	  -->
      <block>
	  <module>rm PrgEnv-intel</module>
	  <module>rm PrgEnv-cray</module>
	  <module>rm PrgEnv-gnu</module>
	  <module>rm intel</module>
	  <module>rm cce</module>
	  <module>rm cray-parallel-netcdf</module>
	  <module>rm cray-parallel-hdf5</module>
	  <module>rm pmi</module>
	  <module>rm cray-libsci</module>
	  <module>rm cray-mpich2</module>
	  <module>rm cray-netcdf</module>
	  <module>rm cray-hdf5</module>
	  <module>rm cray-netcdf-hdf5parallel</module>
	  <module>rm craype-sandybridge</module>
	  <module>rm craype-ivybridge</module>
      <module>swap craype craype/2.1.1</module>
	  <module>load craype-ivybridge</module>
	  <module>load altd/2.0</module>
	  <module>load cmake/2.8.11.2</module>
      <module>load cray-netcdf-hdf5parallel/4.3.0</module>
      <module>load cray-hdf5-parallel/1.8.11</module>
      <module>load cray-parallel-netcdf/1.3.1.1</module>
 	</block>
	<block compiler="intel">
      <module>load PrgEnv-intel</module>
      <module>switch intel intel/13.1.3.192</module>
      <module>rm cray-libsci</module>
      <env name="MKL">-mkl=cluster</env>
	  <module>use /global/project/projectdirs/ccsm1/modulefiles/edison</module>
	  <block debug="TRUE">
        <module>load esmf/6.2.0-defio-mpi-g</module>
      </block>
	  <block debug="FALSE">
        <module>load esmf/6.2.0-defio-mpi-O</module>
      </block>
    </block>
	<block compiler="cray">
      <module>load cray-libsci/12.2.0</module>
	  <module>switch cce cce/8.1.9</module>
    </block>
	<block compiler="gnu">
      <module>load cray-libsci/12.2.0</module>
	  <module>switch gcc gcc/4.8.0</module>
    </block>
	<block mpilib="mpi-serial">
	   <module>unload cray-netcdf-hdf5parallel/4.3.0</module>
	   <module>unload cray-hdf5-parallel/1.8.11</module>
	   <module>unload cray-parallel-netcdf/1.3.1.1</module>
	   <module>load cray-hdf5/1.8.11</module>
	   <module>load cray-netcdf/4.3.0</module>
    </block>
	
  </machine>
  <machine mach="janus">
        <module_system>module</module_system>
        <init_path lang="perl">/usr/share/Modules/init/perl.pm</init_path>
        <cmd_path lang="perl">/usr/bin/modulecmd perl </cmd_path>
        <block compiler="intel">
          <module>load intel/intel-13.0.0</module>
          <module>load openmpi/openmpi-1.7.3_intel-13.0.0_ib</module>
          <module>load netcdf/netcdf4-4.3_hdf5-1.8.11_szip-2.1_zlib-1.2.78_jpeglib-8d_intel-13.0.0</module>
          <module>load pnetcdf/pnetcdf-1.3.1_openmpi-1.6.4_intel-13.0.0_ib</module>
          <module>load perl/perl-5.16.2</module>
          <module>load cmake/cmake-2.8.10.2</module>
          <module>load slurm/slurm</module>
        </block>
        <module>load slurm/slurm</module>
        <env name="USER_INCLDIR"></env>
        <env name="NETCDF_PATH">$NETCDF</env>
        <env name="PNETCDF_PATH">$PNETCDF</env>
        <env name="PERL5LIB">"/lustre/janus_scratch/cesm/perlmodules/lib/site_perl/5.16.2:/lustre/janus_scratch/cesm/perlmodules/lib/site_perl/5.16.2/x86_64-linux"</env>
        <env name="OMP_STACKSIZE">64M</env>
  </machine>
  <machine mach="goldbach">
  	<module_system>module</module_system>
  	<init_path lang="perl">/usr/share/Modules/init/perl.pm</init_path>
  	<cmd_path lang="perl">/usr/bin/modulecmd perl </cmd_path>
  	<block compiler="intel">
	  <module>load compiler/intel/13.1.2</module>
  	</block>
  	<block compiler="pgi">
	  <module>load compiler/pgi/14.1</module>
  	</block>
  	<block compiler="nag">
	  <module>load compiler/nag/5.3.1-907</module>
  	</block>
  	<block compiler="gnu">
	  <module>load compiler/gnu/4.4.7</module>
  	</block>
  </machine>
  <machine mach="mira">
    <module_system>soft</module_system>
    <init_path lang="perl">. /etc/profile.d/00softenv.sh</init_path>
    <cmd_path lang="perl">soft</cmd_path>
    <env name="OMP_DYNAMIC">FALSE</env>
    <env name="AIX_THREADSCOPE">S</env>
    <env name="MPI_TYPE_MAX">100000</env>
    <env name="XLSMPOPTS">stack=86000000</env>
    <module>add +mpiwrapper-xl</module>
    <module>add @ibm-compilers-2014-02</module>
  </machine>

  <machine mach="yellowstone">
    <module_system>module</module_system>
    <init_path lang="perl">/glade/apps/opt/lmod/lmod/init/perl</init_path>
    <cmd_path lang="perl">/glade/apps/opt/lmod/lmod/libexec/lmod perl </cmd_path>
    <block>
      <module>unload intel</module>
      <module>unload netcdf</module>
      <module>load ncarenv/1.0</module>
      <module>load ncarbinlibs/1.1</module>
      <module>spider ncarcompilers</module>
      <module>load ncarcompilers/1.0</module>
      <module>load cmake/2.8.10.2</module>
      <module>load perlmods</module>
      <module>load python/2.7.7</module>
      <module>load all-python-libs</module> 
      <module mpilib="mpich2">load pnetcdf/1.4.1</module>
      <module mpilib="pempi">load pnetcdf/1.4.1</module>
      <module debug="TRUE">load debug</module>
      <module debug="TRUE">load totalview</module>
    </block>
    <block compiler="intel">
      <module>load intel intel/14.0.2</module>
      <module>load mkl/11.1.2</module>
      <module>load trilinos/11.10.2</module>
      <block mpilib="mpi-serial">
      	<module mpilib="mpi-serial">load netcdf/4.3.0</module>
	  </block>
      <module mpilib="mpich2">load netcdf-mpi/4.3.0</module>
      <module mpilib="pempi">load netcdf-mpi/4.3.0</module>
      <module>load esmf</module>
      <module mpilib="mpi-serial" debug="TRUE">load esmf-5.3.0-ncdfio-uni-g</module>
      <module mpilib="mpi-serial" debug="FALSE">load esmf-5.3.0-ncdfio-uni-O</module>
      <module mpilib="mpich2" debug="TRUE">load esmf-5.3.0-defio-mpi-g</module>
      <module mpilib="mpich2" debug="FALSE">load esmf-5.3.0-defio-mpi-O</module>
      <module mpilib="pempi" debug="TRUE">load esmf-5.3.0-defio-mpi-g</module>
      <module mpilib="pempi" debug="FALSE">load esmf-5.3.0-defio-mpi-O</module>
    </block>
    <block compiler="pgi">
      <module>load pgi/13.3</module>
      <module>load netcdf/4.3.0</module>
    </block>
    <block compiler="gnu">
      <module>load gnu/4.8.0</module>
      <module>load netcdf/4.3.0</module>
    </block>
    <block>
      <env name="OMP_STACKSIZE">256M</env>
      <!-- MPI Environment. -->
      <env name="MP_LABELIO">yes</env>
      <env name="MP_INFOLEVEL">2</env>
      <env name="MP_SHARED_MEMORY">yes</env>
      <env name="MP_EUILIB">us</env>
      <env name="MP_MPILIB">${MPILIB}</env>
      <env name="MP_STDOUTMODE">unordered</env>
      <env name="MP_RC_USE_LMC">yes</env>
      <env debug="TRUE" name="MP_EUIDEVELOP">yes</env>
      <env debug="FALSE" name="MP_EUIDEVELOP">min</env>
      <env name="MP_EAGER_LIMIT">0</env>
    </block>
  </machine>
</config_env>
