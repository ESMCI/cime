<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>10. Testing Cases &mdash; CIME master documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=30d551ce"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11. Troubleshooting" href="troubleshooting.html" />
    <link rel="prev" title="9. CIME config and hooks" href="cime-customize.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            CIME
          </a>
              <div class="version">
                master
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../what_cime/index.html">What is CIME?</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Using the Case Control System</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction-and-overview.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="create-a-case.html">2. Creating a Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="setting-up-a-case.html">3. Setting up a Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="building-a-case.html">4. Building a Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="running-a-case.html">5. Running a Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="cloning-a-case.html">6. Cloning a Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="cime-change-namelist.html">7. Customizing your input variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="cime-config.html">8. CIME user config directory</a></li>
<li class="toctree-l2"><a class="reference internal" href="cime-customize.html">9. CIME config and hooks</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">10. Testing Cases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#testname-syntax">10.1. Testname syntax</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#testtype">10.1.1. TESTTYPE</a></li>
<li class="toctree-l4"><a class="reference internal" href="#testtype-modifiers">10.1.2. Testtype Modifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#test-case-modifiers">10.1.3. Test Case Modifiers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#test-progress-and-output">10.2. Test progress and output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#running-multiple-tests-and-other-command-line-examples">10.3. Running multiple tests and other command line examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="#test-control-with-xml-files">10.4. Test control with XML files</a></li>
<li class="toctree-l3"><a class="reference internal" href="#test-control-with-python-dictionaries">10.5. Test control with python dictionaries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-test-output">10.6. Create_test output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#baselines-and-baseline-testing">10.7. Baselines and Baseline Testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#creating-a-baseline">10.7.1. Creating a baseline</a></li>
<li class="toctree-l4"><a class="reference internal" href="#comparing-a-baseline">10.7.2. Comparing a baseline</a></li>
<li class="toctree-l4"><a class="reference internal" href="#managing-baselines">10.7.3. Managing baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="#performance-baselines">10.7.4. Performance baselines</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html">11. Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#configuring-the-case-control-system">Configuring the Case Control System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build_cpl/index.html">Building a Coupled Model with CIME</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc_tools/index.html">Miscellaneous Tools</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../glossary/index.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools_user/index.html">User Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../xml_files/index.html">XML Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CIME_api/modules.html">CIME</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Tools_api/modules.html">Tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">CIME</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Using the Case Control System</a></li>
      <li class="breadcrumb-item active"><span class="section-number">10. </span>Testing Cases</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/users_guide/testing.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="testing-cases">
<span id="testing"></span><h1><span class="section-number">10. </span>Testing Cases<a class="headerlink" href="#testing-cases" title="Link to this heading"></a></h1>
<p><a class="reference external" href="../Tools_user/create_test.html">create_test</a>
is a powerful system testing capability provided by the CIME Case Control System.
create_test can, in one command, create a case, setup, build and run the case
according to the test type and return a PASS or FAIL for the test result.</p>
<p id="individual">An individual test can be run as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$CIMEROOT/scripts/create_test $test_name
</pre></div>
</div>
<p>Everything the test will do is controlled by parsing the test name.</p>
<section id="testname-syntax">
<h2><span class="section-number">10.1. </span>Testname syntax<a class="headerlink" href="#testname-syntax" title="Link to this heading"></a></h2>
<p id="test-naming">Tests must be named with the following forms, [ ]=optional:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TESTTYPE</span><span class="p">[</span><span class="n">_MODIFIERS</span><span class="p">]</span><span class="o">.</span><span class="n">GRID</span><span class="o">.</span><span class="n">COMPSET</span><span class="p">[</span><span class="o">.</span><span class="n">MACHINE_COMPILER</span><span class="p">][</span><span class="o">.</span><span class="n">GROUP</span><span class="o">-</span><span class="n">TESTMODS</span><span class="p">]</span>
</pre></div>
</div>
<p>For example using the minimum required elements of a testname:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$CIMEROOT/scripts/create_test ERP.ne4pg2_oQU480.F2010
</pre></div>
</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>NAME PART</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="#testtype">TESTTYPE</a></p></td>
<td><p>the general type of test, e.g. SMS. Options are listed in the following table and config_tests.xml.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#modifiers">MODIFIERS</a></p></td>
<td><p>Changes to the default settings for the test type.
See the following table and test_scheduler.py.</p></td>
</tr>
<tr class="row-even"><td><p>GRID</p></td>
<td><p>The grid set (usually a grid alias).</p></td>
</tr>
<tr class="row-odd"><td><p>COMPSET</p></td>
<td><p>The compset, Can be a longname but usually a compset alias</p></td>
</tr>
<tr class="row-even"><td><p>MACHINE</p></td>
<td><p>This is optional; if this value is not supplied, <a class="reference external" href="../Tools_user/create_test.html">create_test</a>
will probe the underlying machine.</p></td>
</tr>
<tr class="row-odd"><td><p>COMPILER</p></td>
<td><p>If this value is not supplied, use the default compiler for MACHINE.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#group-testmods">GROUP-TESTMODS</a></p></td>
<td><p>This is optional. This points to a directory with  <code class="docutils literal notranslate"><span class="pre">user_nl_xxx</span></code> files or a <code class="docutils literal notranslate"><span class="pre">shell_commands</span></code>
that can be used to make namelist and other  modifications prior to running a test.</p></td>
</tr>
</tbody>
</table>
<section id="testtype">
<span id="id2"></span><h3><span class="section-number">10.1.1. </span>TESTTYPE<a class="headerlink" href="#testtype" title="Link to this heading"></a></h3>
<p>The test types in CIME are all system tests: they compile all the code needed in a case, They test
functionality of the model such as restart capability, invariance with MPI task count, and short
term archiving. At this time, they do not test for scientific correctness.</p>
<p>The currently supported test types are:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>TESTTYPE</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ERS</p></td>
<td><dl>
<dt>Exact restart from startup (default 6 days + 5 days)</dt><dd><div class="line-block">
<div class="line">Do an 11 day initial test - write a restart at day 6.    (file suffix: base)</div>
<div class="line">Do a 5 day restart test, starting from restart at day 6. (file suffix: rest)</div>
<div class="line">Compare component history files ‘.base’ and ‘.rest’ at day 11 with cprnc</div>
<div class="line-block">
<div class="line">PASS if they are identical.</div>
</div>
</div>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>ERS2</p></td>
<td><p>Exact restart from startup  (default 6 days + 5 days).</p>
<blockquote>
<div><div class="line-block">
<div class="line">Do an 11 day initial test without making restarts. (file suffix: base)</div>
<div class="line">Do an 11 day restart test stopping at day 6 with a restart,
then resuming from restart at day 6. (file suffix: rest)</div>
<div class="line">Compare component history files “.base” and “.rest” at day 11.</div>
</div>
</div></blockquote>
</td>
</tr>
<tr class="row-even"><td><p>ERT</p></td>
<td><p>Longer version of ERS. Exact restart from startup, default 2 month + 1 month (ERS with info DBUG = 1).</p></td>
</tr>
<tr class="row-odd"><td><p>IRT</p></td>
<td><p>Exact restart from startup, (default 4 days + 7 days) with restart from interim file.</p></td>
</tr>
<tr class="row-even"><td><p>ERIO</p></td>
<td><p>Exact restart from startup with different IO file types, (default 6 days + 5 days).</p></td>
</tr>
<tr class="row-odd"><td><p>ERR</p></td>
<td><p>Exact restart from startup with resubmit, (default 4 days + 3 days).</p></td>
</tr>
<tr class="row-even"><td><p>ERRI</p></td>
<td><p>Exact restart from startup with resubmit, (default 4 days + 3 days). Tests incomplete logs option for st_archive.</p></td>
</tr>
<tr class="row-odd"><td><p>ERI</p></td>
<td><dl class="simple">
<dt>hybrid/branch/exact restart test, default (by default STOP_N is 22 days)</dt><dd><dl class="simple">
<dt>ref1case</dt><dd><p>Do an initial run for 3 days writing restarts at day 3.
ref1case is a clone of the main case.
Short term archiving is on.</p>
</dd>
<dt>ref2case (Suffix hybrid)</dt><dd><p>Do a hybrid run for default 19 days running with ref1 restarts from day 3,
and writing restarts at day 10.
ref2case is a clone of the main case.
Short term archiving is on.</p>
</dd>
<dt>case</dt><dd><p>Do a branch run, starting from restarts written in ref2case,
for 9 days and writing restarts at day 5.
Short term archiving is off.</p>
</dd>
<dt>case (Suffix base)</dt><dd><p>Do a restart run from the branch run restarts for 4 days.
Compare component history files ‘.base’ and ‘.hybrid’ at day 19.
Short term archiving is off.</p>
</dd>
</dl>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>ERP</p></td>
<td><dl class="simple">
<dt>PES counts hybrid (OPENMP/MPI) restart bit for bit test from startup, (default 6 days + 5 days).</dt><dd><p>Initial PES set up out of the box
Do an 11 day initial test - write a restart at day 6.     (file suffix base)
Half the number of tasks and threads for each component.
Do a 5 day restart test starting from restart at day 6. (file suffix rest)
Compare component history files ‘.base’ and ‘.rest’ at day 11.
This is just like an ERS test but the tasks/threading counts are modified on restart</p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>PEA</p></td>
<td><dl class="simple">
<dt>Single PE bit for bit test (default 5 days)</dt><dd><p>Do an initial run on 1 PE with mpi library.     (file suffix: base)
Do the same run on 1 PE with mpiserial library. (file suffix: mpiserial)
Compare base and mpiserial.</p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>PEM</p></td>
<td><dl class="simple">
<dt>Modified PE counts for MPI(NTASKS) bit for bit test (default 5 days)</dt><dd><p>Do an initial run with default PE layout                                     (file suffix: base)
Do another initial run with modified PE layout (NTASKS_XXX =&gt; NTASKS_XXX/2)  (file suffix: modpes)
Compare base and modpes</p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>PET</p></td>
<td><dl class="simple">
<dt>Modified threading OPENMP bit for bit test (default 5 days)</dt><dd><p>Do an initial run where all components are threaded by default. (file suffix: base)
Do another initial run with NTHRDS=1 for all components.        (file suffix: single_thread)
Compare base and single_thread.</p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>PFS</p></td>
<td><p>Performance test setup. History and restart output is turned off. (default 20 days)</p></td>
</tr>
<tr class="row-odd"><td><p>ICP</p></td>
<td><p>CICE performance test.</p></td>
</tr>
<tr class="row-even"><td><p>OCP</p></td>
<td><p>POP performance test. (default 10 days)</p></td>
</tr>
<tr class="row-odd"><td><p>MCC</p></td>
<td><p>Multi-driver validation vs single-driver (both multi-instance). (default 5 days)</p></td>
</tr>
<tr class="row-even"><td><p>NCK</p></td>
<td><dl class="simple">
<dt>Multi-instance validation vs single instance - sequential PE for instances (default length)</dt><dd><p>Do an initial run test with NINST 1. (file suffix: base)
Do an initial run test with NINST 2. (file suffix: multiinst for both _0001 and _0002)
Compare base and _0001 and _0002.</p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>REP</p></td>
<td><p>Reproducibility: Two identical initial runs are bit for bit. (default 5 days)</p></td>
</tr>
<tr class="row-even"><td><p>SBN</p></td>
<td><p>Smoke build-namelist test (just run preview_namelist and check_input_data).</p></td>
</tr>
<tr class="row-odd"><td><p>SMS</p></td>
<td><dl class="simple">
<dt>Smoke test (default 5 days)</dt><dd><p>Do a 5 day initial test that runs to completing without error. (file suffix: base)</p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>SEQ</p></td>
<td><dl class="simple">
<dt>Different sequencing bit for bit test. (default 10 days)</dt><dd><p>Do an initial run test with out-of-box PE-layout. (file suffix: base)
Do a second run where all root pes are at pe-0.   (file suffix: seq)
Compare base and seq.</p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>DAE</p></td>
<td><p>Data assimilation test, default 1 day, two DA cycles, no data modification.</p></td>
</tr>
<tr class="row-even"><td><p>PRE</p></td>
<td><dl class="simple">
<dt>Pause-resume test: by default a bit for bit test of pause-resume cycling.</dt><dd><p>Default 5 hours, five pause/resume cycles, no data modification.</p>
</dd>
</dl>
<div class="line-block">
<div class="line"><br /></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The tests run for a default length indicated above, will use default pelayouts for the case
on the machine the test runs on and its default coupler and MPI library. Its possible to modify
elements of the test through a test type modifier.</p>
</section>
<section id="testtype-modifiers">
<span id="modifiers"></span><h3><span class="section-number">10.1.2. </span>Testtype Modifiers<a class="headerlink" href="#testtype-modifiers" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>MODIFIERS</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>_C#</p></td>
<td><p>Set number of instances to # and use the multi driver (can’t use with _N).</p></td>
</tr>
<tr class="row-odd"><td><p>_CG</p></td>
<td><p>CALENDAR set to “GREGORIAN”</p></td>
</tr>
<tr class="row-even"><td><p>_D</p></td>
<td><p>XML variable DEBUG set to “TRUE”</p></td>
</tr>
<tr class="row-odd"><td><p>_I</p></td>
<td><p>Marker to distinguish tests with same name - ignored.</p></td>
</tr>
<tr class="row-even"><td><p>_Lo#</p></td>
<td><dl>
<dt>Run length set by o (STOP_OPTION) and # (STOP_N).</dt><dd><div class="line-block">
<div class="line">o = {“y”:”nyears”, “m”:”nmonths”,  “d”:”ndays”,</div>
<div class="line-block">
<div class="line">“h”:”nhours”, “s”:”nseconds”, “n”:”nsteps”}</div>
</div>
</div>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>_Mx</p></td>
<td><p>Set MPI library to x.</p></td>
</tr>
<tr class="row-even"><td><p>_N#</p></td>
<td><p>Set number of instances to # and use a single driver (can’t use with _C).</p></td>
</tr>
<tr class="row-odd"><td><p>_Px</p></td>
<td><p>Set create_newcase’s <code class="docutils literal notranslate"><span class="pre">--pecount</span></code> to x, which is usually N (tasks) or NxM (tasks x threads per task).</p></td>
</tr>
<tr class="row-even"><td><p>_R</p></td>
<td><p>For testing in PTS_MODE or Single Column Model (SCM) mode.
For PTS_MODE, compile with mpi-serial.</p></td>
</tr>
<tr class="row-odd"><td><p>_Vx</p></td>
<td><dl>
<dt>Set driver to x.</dt><dd><div class="line-block">
<div class="line"><br /></div>
</div>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p>For example, this will run the ERP test with debugging turned on during compilation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CIMEROOT</span><span class="o">/</span><span class="n">scripts</span><span class="o">/</span><span class="n">create_test</span> <span class="n">ERP_D</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span>
</pre></div>
</div>
<p>This will run the ERP test for 3 days instead of the default 11 days:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CIMEROOT</span><span class="o">/</span><span class="n">scripts</span><span class="o">/</span><span class="n">create_test</span> <span class="n">ERP_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span>
</pre></div>
</div>
<p>You can combine testtype modifiers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CIMEROOT</span><span class="o">/</span><span class="n">scripts</span><span class="o">/</span><span class="n">create_test</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span>
</pre></div>
</div>
</section>
<section id="test-case-modifiers">
<h3><span class="section-number">10.1.3. </span>Test Case Modifiers<a class="headerlink" href="#test-case-modifiers" title="Link to this heading"></a></h3>
<p id="group-testmods">create_test runs with out-of-the-box compsets and grid sets. Sometimes you may want to run a test with
modification to a namelist or other setting without creating an entire compset. CCS provides the testmods
capability for this situation.</p>
<p>A testmod is a string at the end of the full testname (including machine and compiler)
with the form GROUP-TESTMODS which are parsed by create_test as follows:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>TESTMOD</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>GROUP</p></td>
<td><p>Define the subdirectory of testmods_dirs and the parent directory of various testmods.</p></td>
</tr>
<tr class="row-odd"><td><p>TESTMODS</p></td>
<td><p>A subdirectory of GROUP containing files which set non-default values
of the set-up and run-time variables via namelists or xml_change commands.
Example:</p>
<blockquote>
<div><div class="line-block">
<div class="line">GROUP-TESTMODS = cam-outfrq9s points to</div>
<div class="line-block">
<div class="line">$cesm/components/cam/cime_config/testdefs/testmods_dirs/cam/outfrq9s</div>
</div>
<div class="line">while allactive-defaultio points to</div>
<div class="line-block">
<div class="line">$cesm/cime_config/testmods_dirs/allactive/defaultio</div>
</div>
</div>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p>For example, the ERP test for an E3SM F-case can be modified to use a different radiation scheme:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CIMEROOT</span><span class="o">/</span><span class="n">scripts</span><span class="o">/</span><span class="n">create_test</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">pm</span><span class="o">-</span><span class="n">cpu_intel</span><span class="o">.</span><span class="n">eam</span><span class="o">-</span><span class="n">rrtmgp</span>
</pre></div>
</div>
<p>This tells create_test to look in $e3sm/components/eam/cime_config/testdefs/testmods_dirs/eam/rrtmpg
where it finds the following lines in the shell_commands file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="o">./</span><span class="n">xmlchange</span> <span class="o">--</span><span class="n">append</span> <span class="n">CAM_CONFIG_OPTS</span><span class="o">=</span><span class="s1">&#39;-rad rrtmgp&#39;</span>
</pre></div>
</div>
<p>These commands are applied after the testcase is created and case.setup is called.</p>
<p>The contents of each testmods directory can include</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>user_nl_$components    namelist variable=value pairs
shell_commands         xmlchange commands
user_mods              a list of other GROUP-TESTMODS which should be imported
                       but at a lower precedence than the local testmods.
</pre></div>
</div>
<p>eam/cime_config/testdefs/testmods_dirs/eam contains modifications for eam in an F-case test.  You
might make a directory called eam/cime_config/testdefs/testmods_dirs/elm to modify the land model
in an F-case test.</p>
<p>The “rrtmpg” directory contains the actual testmods to apply.
Note; do not use ‘-’ in the testmods directory name because it has a special meaning to create_test.</p>
</section>
</section>
<section id="test-progress-and-output">
<h2><span class="section-number">10.2. </span>Test progress and output<a class="headerlink" href="#test-progress-and-output" title="Link to this heading"></a></h2>
<p>Each test run by <a class="reference external" href="../Tools_user/create_test.html">create_test</a>  includes the following mandatory steps:</p>
<ul class="simple">
<li><p>CREATE_NEWCASE: creating the create</p></li>
<li><p>XML: xml changes to case based on test settings</p></li>
<li><p>SETUP: setup case (case.setup)</p></li>
<li><p>SHAREDLIB_BUILD: build sharedlibs</p></li>
<li><p>MODEL_BUILD: build module (case.build)</p></li>
<li><p>SUBMIT: submit test (case.submit)</p></li>
<li><p>RUN: run test test</p></li>
</ul>
<p>And the following optional phases:</p>
<ul class="simple">
<li><p>NLCOMP: Compare case namelists against baselines</p></li>
<li><p>THROUGHPUT: Compare throughput against baseline throughput</p></li>
<li><p>MEMCOMP: Compare memory usage against baseline memory usage</p></li>
<li><p>MEMLEAK: Check for memleak</p></li>
<li><p>COMPARE: Used to track test-specific comparions, for example, an ERS test would have a COMPARE_base_rest phase representing the check that the base result matched the restart result.</p></li>
<li><p>GENERATE: Generate baseline results</p></li>
<li><p>BASELINE: Compare results against baselines</p></li>
</ul>
<p>Each phase within the test may be in one of the following states:</p>
<ul class="simple">
<li><p>PASS: The phase was executed successfully</p></li>
<li><p>FAIL: We attempted to execute this phase, but it failed. If this phase is mandatory, no further progress will be made on this test. A detailed explanation of the failure should be in TestStatus.log.</p></li>
<li><p>PEND: This phase will be run or is currently running but not complete</p></li>
</ul>
</section>
<section id="running-multiple-tests-and-other-command-line-examples">
<h2><span class="section-number">10.3. </span>Running multiple tests and other command line examples<a class="headerlink" href="#running-multiple-tests-and-other-command-line-examples" title="Link to this heading"></a></h2>
<p>Multiple tests can be run by listing all of the test names on the command line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$CIMEROOT/scripts/create_test  $test_name  $test_name2
</pre></div>
</div>
<p>or by putting the test names into a file, one name per line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$CIMEROOT/scripts/create_test -f $file_of_test_names
</pre></div>
</div>
<p>To run a test with a non-default compiler:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">create_test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span> <span class="o">--</span><span class="n">compiler</span> <span class="n">intel</span>
</pre></div>
</div>
<p>To run a test with baseline comparisons against baseline name ‘master’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">create_test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span> <span class="o">-</span><span class="n">c</span> <span class="o">-</span><span class="n">b</span> <span class="n">master</span>
</pre></div>
</div>
<p>To run a test and update baselines with baseline name ‘master’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">create_test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span> <span class="o">-</span><span class="n">g</span> <span class="o">-</span><span class="n">b</span> <span class="n">master</span>
</pre></div>
</div>
<p>To run a test with a non-default test-id:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">create_test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span> <span class="o">-</span><span class="n">t</span> <span class="n">my_test_id</span>
</pre></div>
</div>
<p>To run a test and use a non-default test-root for your case dir:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>./create_test SMS.f19_f19.A -t $test_root
</pre></div>
</div>
<p>To run a test and use and put case, build, and run dirs all in the same root:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>./create_test SMS.f19_f19.A --output-root $output_root
</pre></div>
</div>
<p>To run a test and force it to go into a certain batch queue:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">create_test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span> <span class="o">-</span><span class="n">q</span> <span class="n">myqueue</span>
</pre></div>
</div>
<p>The Case Control System supports more sophisticated ways to specify a suite of tests and
how they should be run.  One approach uses XML files and the other uses python dictionaries.</p>
</section>
<section id="test-control-with-xml-files">
<h2><span class="section-number">10.4. </span>Test control with XML files<a class="headerlink" href="#test-control-with-xml-files" title="Link to this heading"></a></h2>
<p id="query-testlists">A pre-defined suite of tests can by run using the <code class="docutils literal notranslate"><span class="pre">--xml</span></code> options to create_test,
which harvest test names from testlist*.xml files.
As described in <a class="reference external" href="https://github.com/ESCOMP/ctsm/wiki/System-Testing-Guide">https://github.com/ESCOMP/ctsm/wiki/System-Testing-Guide</a>,
to determine what pre-defined test suites are available and what tests they contain,
you can run <a class="reference internal" href="#query-testlists">query_testlists</a>.</p>
<p>Test suites are retrieved in create_test via 3 selection attributes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">xml</span><span class="o">-</span><span class="n">category</span> <span class="n">your_category</span>   <span class="n">The</span> <span class="n">test</span> <span class="n">category</span><span class="o">.</span>
<span class="o">--</span><span class="n">xml</span><span class="o">-</span><span class="n">machine</span>  <span class="n">your_machine</span>    <span class="n">The</span> <span class="n">machine</span><span class="o">.</span>
<span class="o">--</span><span class="n">xml</span><span class="o">-</span><span class="n">compiler</span> <span class="n">your_compiler</span>   <span class="n">The</span> <span class="n">compiler</span><span class="o">.</span>
</pre></div>
</div>
<div class="line-block">
<div class="line">If none of these 3 are used, the default values are ‘none’.</div>
<div class="line">If any of them are used, the default for the unused options is ‘all’.</div>
<div class="line">Existing values of these attributes can be seen by running <a class="reference internal" href="#query-testlists">query_testlists</a>.</div>
</div>
<p>The search for test names can be restricted to a single test list using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">xml</span><span class="o">-</span><span class="n">testlist</span> <span class="n">your_testlist</span>
</pre></div>
</div>
<p>Omitting this results in searching all testlists listed in:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cime</span><span class="o">/</span><span class="n">config</span><span class="o">/</span><span class="p">{</span><span class="n">cesm</span><span class="p">,</span><span class="n">e3sm</span><span class="p">}</span><span class="o">/</span><span class="n">config_files</span><span class="o">.</span><span class="n">xml</span>
</pre></div>
</div>
<p><strong>$CIMEROOT/scripts/query_testlists</strong> gathers descriptions of the tests and testlists available
in the XML format, the components, and projects.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">--xml-{compiler,machine,category,testlist}</span></code> arguments can be used
as in create_test (above) to focus the search.
The ‘category’ descriptor of a test can be used to run a group of associated tests at the same time.
The available categories, with the tests they encompass, can be listed by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">query_testlists</span> <span class="o">--</span><span class="n">define</span><span class="o">-</span><span class="n">testtypes</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">--show-options</span></code> argument does the same, but displays the ‘options’ defined for the tests,
such as queue, walltime, etc..</p>
<p>Adding a test requires first deciding which compset will be tested
and then finding the appropriate testlist_$component.xml file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>components/$component/cime_config/testdefs/
   testlist_$component.xml
   testmods_dirs/$component/{TESTMODS1,TESTMODS2,...}
cime_config/
   testlist_allactive.xml
   testmods_dirs/allactive/{defaultio,...}
</pre></div>
</div>
<p>You can optionally add testmods for that test in the testmods_dirs.
Testlists and testmods live in different paths for cime, drv, and components.</p>
<p>If this test will only be run as a single test, you can now create a test name
and follow the <a class="reference internal" href="#individual">individual</a> test instructions for create_test.</p>
</section>
<section id="test-control-with-python-dictionaries">
<h2><span class="section-number">10.5. </span>Test control with python dictionaries<a class="headerlink" href="#test-control-with-python-dictionaries" title="Link to this heading"></a></h2>
<p id="python-dict-testing">One can also define suites of tests in a file called tests.py typically located in $MODEL/cime_config/tests.py</p>
<p>To run a test suite called e3sm_developer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">create_test</span> <span class="n">e3sm_developer</span>
</pre></div>
</div>
<p>One can exclude a specific test from a suite:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">create_test</span> <span class="n">e3sm_developer</span> <span class="o">^</span><span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span>
</pre></div>
</div>
<p>See create_test -h for the full list of options
`</p>
<p>To add a test, open the MODEL/cime_config/tests.py file, you’ll see a python dict at the top
of the file called _TESTS, find the test category you want to
change in this dict and add your testcase to the list.  Note the
comment at the top of this file indicating that you add a test with
this format: test&gt;.&lt;grid&gt;.&lt;compset&gt;, and then there is a second
argument for mods.  Machine and compiler are added later depending on where
create_test is invoked and its arguments.</p>
<p>Existing tests can be listed using the cime/CIME/Tools/list_e3sm_tests script.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">list_e3sm_tests</span> <span class="o">-</span><span class="n">t</span> <span class="n">compsets</span> <span class="n">e3sm_developer</span>
</pre></div>
</div>
<p>Will list all the compsets tested in the e3sm_developer test suite.</p>
</section>
<section id="create-test-output">
<h2><span class="section-number">10.6. </span>Create_test output<a class="headerlink" href="#create-test-output" title="Link to this heading"></a></h2>
<p>Interpreting test output is pretty easy. Looking at an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span> <span class="o">./</span><span class="n">create_test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span>

<span class="n">Creating</span> <span class="n">test</span> <span class="n">directory</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jgfouca</span><span class="o">/</span><span class="n">e3sm</span><span class="o">/</span><span class="n">scratch</span><span class="o">/</span><span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span><span class="mf">.20170504_163152_31</span><span class="n">aahy</span>
<span class="n">RUNNING</span> <span class="n">TESTS</span><span class="p">:</span>
  <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span>
<span class="n">Starting</span> <span class="n">CREATE_NEWCASE</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="k">with</span> <span class="mi">1</span> <span class="n">procs</span>
<span class="n">Finished</span> <span class="n">CREATE_NEWCASE</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="ow">in</span> <span class="mf">4.170537</span> <span class="n">seconds</span> <span class="p">(</span><span class="n">PASS</span><span class="p">)</span>
<span class="n">Starting</span> <span class="n">XML</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="k">with</span> <span class="mi">1</span> <span class="n">procs</span>
<span class="n">Finished</span> <span class="n">XML</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="ow">in</span> <span class="mf">0.735993</span> <span class="n">seconds</span> <span class="p">(</span><span class="n">PASS</span><span class="p">)</span>
<span class="n">Starting</span> <span class="n">SETUP</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="k">with</span> <span class="mi">1</span> <span class="n">procs</span>
<span class="n">Finished</span> <span class="n">SETUP</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="ow">in</span> <span class="mf">11.544286</span> <span class="n">seconds</span> <span class="p">(</span><span class="n">PASS</span><span class="p">)</span>
<span class="n">Starting</span> <span class="n">SHAREDLIB_BUILD</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="k">with</span> <span class="mi">1</span> <span class="n">procs</span>
<span class="n">Finished</span> <span class="n">SHAREDLIB_BUILD</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="ow">in</span> <span class="mf">82.670667</span> <span class="n">seconds</span> <span class="p">(</span><span class="n">PASS</span><span class="p">)</span>
<span class="n">Starting</span> <span class="n">MODEL_BUILD</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="k">with</span> <span class="mi">4</span> <span class="n">procs</span>
<span class="n">Finished</span> <span class="n">MODEL_BUILD</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="ow">in</span> <span class="mf">18.613263</span> <span class="n">seconds</span> <span class="p">(</span><span class="n">PASS</span><span class="p">)</span>
<span class="n">Starting</span> <span class="n">RUN</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="k">with</span> <span class="mi">64</span> <span class="n">procs</span>
<span class="n">Finished</span> <span class="n">RUN</span> <span class="k">for</span> <span class="n">test</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="ow">in</span> <span class="mf">35.068546</span> <span class="n">seconds</span> <span class="p">(</span><span class="n">PASS</span><span class="p">)</span><span class="o">.</span> <span class="p">[</span><span class="n">COMPLETED</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">At</span> <span class="n">test</span><span class="o">-</span><span class="n">scheduler</span> <span class="n">close</span><span class="p">,</span> <span class="n">state</span> <span class="ow">is</span><span class="p">:</span>
<span class="n">PASS</span> <span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span> <span class="n">RUN</span>
  <span class="n">Case</span> <span class="nb">dir</span><span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">jgfouca</span><span class="o">/</span><span class="n">e3sm</span><span class="o">/</span><span class="n">scratch</span><span class="o">/</span><span class="n">SMS</span><span class="o">.</span><span class="n">f19_f19</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">melvin_gnu</span><span class="mf">.20170504_163152_31</span><span class="n">aahy</span>
<span class="n">test</span><span class="o">-</span><span class="n">scheduler</span> <span class="n">took</span> <span class="mf">154.780044079</span> <span class="n">seconds</span>
</pre></div>
</div>
<p>You can see that <a class="reference external" href="../Tools_user/create_test.html">create_test</a>  informs the user of the case directory and of the progress and duration
of the various test phases.</p>
<p>The $CASEDIR for the test will be created in $CIME_OUTPUT_ROOT.  The name will be of the form:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TESTTYPE</span><span class="p">[</span><span class="n">_MODIFIERS</span><span class="p">]</span><span class="o">.</span><span class="n">GRID</span><span class="o">.</span><span class="n">COMPSET</span><span class="o">.</span><span class="n">MACHINE_COMPILER</span><span class="p">[</span><span class="o">.</span><span class="n">GROUP</span><span class="o">-</span><span class="n">TESTMODS</span><span class="p">]</span><span class="o">.</span><span class="n">YYYYMMDD_HHMMSS_hash</span>
</pre></div>
</div>
<p>If MODIFIERS or GROUP-TESTMODS are used, those will be included in the test output directory name.  THe
extra string with YYYYMMDD_HHMMSS_hash is the testid and used to distinquish mulitple runs of the
same test.  That string
can be replaced with the –test-id argument to create_test.</p>
<p>For a test, the $CASEDIR will have $EXEROOT and $RUNDIR as subdirectories.</p>
<p>The current state of a test is represented in the file $CASEDIR/TestStatus.  Example output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">CREATE_NEWCASE</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">XML</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">SETUP</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">SHAREDLIB_BUILD</span> <span class="n">time</span><span class="o">=</span><span class="mi">277</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">MODEL_BUILD</span> <span class="n">time</span><span class="o">=</span><span class="mi">572</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">SUBMIT</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">RUN</span> <span class="n">time</span><span class="o">=</span><span class="mi">208</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">COMPARE_base_rest</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">MEMLEAK</span> <span class="n">insufficient</span> <span class="n">data</span> <span class="k">for</span> <span class="n">memleak</span> <span class="n">test</span>
<span class="n">PASS</span> <span class="n">ERP_D_Ld3</span><span class="o">.</span><span class="n">ne4pg2_oQU480</span><span class="o">.</span><span class="n">F2010</span><span class="o">.</span><span class="n">chrysalis_intel</span> <span class="n">SHORT_TERM_ARCHIVER</span>
</pre></div>
</div>
<p>All other stdout output from the CIME case control system produced by running this test will
be put in the file $CASEDIR/TestStatus.log</p>
<p>A cs.status.$testid script will also be put in the test root. This script will allow you to see the</p>
</section>
<section id="baselines-and-baseline-testing">
<h2><span class="section-number">10.7. </span>Baselines and Baseline Testing<a class="headerlink" href="#baselines-and-baseline-testing" title="Link to this heading"></a></h2>
<p id="baselines">A big part of testing is managing your baselines (sometimes called gold results) and doing additional tests against
the baseline. The baseline for a test will be copy of the (history) files created in the run of the test.</p>
<p>create_test can
be asked to perform bit-for-bit comparisons between the files generated by the current run of the test and
the files stored in the baseline.  They must be bit-for-bit identical for the baseline test to pass.</p>
<p>baseline testing adds an additional
test criteria to the one that comes from the test type and is used as a way to guard against unintentionaly
changing the results from a determinstic climate model.</p>
<section id="creating-a-baseline">
<h3><span class="section-number">10.7.1. </span>Creating a baseline<a class="headerlink" href="#creating-a-baseline" title="Link to this heading"></a></h3>
<p id="id5">A baseline can be generated by passing <code class="docutils literal notranslate"><span class="pre">-g</span></code> to <a class="reference external" href="../Tools_user/create_test.html">create_test</a>. There
are additional options to control generating baselines.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">scripts</span><span class="o">/</span><span class="n">create_test</span> <span class="o">-</span><span class="n">b</span> <span class="n">master</span> <span class="o">-</span><span class="n">g</span> <span class="n">SMS</span><span class="o">.</span><span class="n">ne30_f19_g16_rx1</span><span class="o">.</span><span class="n">A</span>
</pre></div>
</div>
</section>
<section id="comparing-a-baseline">
<h3><span class="section-number">10.7.2. </span>Comparing a baseline<a class="headerlink" href="#comparing-a-baseline" title="Link to this heading"></a></h3>
<p id="id7">Comparing the output of a test to a baseline is achieved by passing <code class="docutils literal notranslate"><span class="pre">-c</span></code> to <a class="reference external" href="../Tools_user/create_test.html">create_test</a>.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">scripts</span><span class="o">/</span><span class="n">create_test</span> <span class="o">-</span><span class="n">b</span> <span class="n">master</span> <span class="o">-</span><span class="n">c</span> <span class="n">SMS</span><span class="o">.</span><span class="n">ne30_f19_g16_rx1</span><span class="o">.</span><span class="n">A</span>
</pre></div>
</div>
<p>Suppose you accidentally changed something in the source code that does not cause the model to crash but
does cause it to change the answers it produces.  In this case, the SMS test would pass (it still runs) but the
comparison with baselines would FAIL (answers are not bit-for-bit identical to the baseline) and so the test
as a whole would FAIL.</p>
</section>
<section id="managing-baselines">
<h3><span class="section-number">10.7.3. </span>Managing baselines<a class="headerlink" href="#managing-baselines" title="Link to this heading"></a></h3>
<p id="id9">If you intended to change the answers, you need to update the baseline with new files.  This is referred to
as “blessing” the test.
This is done with the <a class="reference external" href="../Tools_user/bless_test_results.html">bless_test_results</a> tool. The tool provides the ability to bless different features of the baseline. The currently supported features are namelist files, history files, and performance metrics. The performance metrics are separated into throughput and memory usage.</p>
<p>The following command can be used to compare a test to a baseline and bless an update to the history file.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">CIME</span><span class="o">/</span><span class="n">Tools</span><span class="o">/</span><span class="n">bless_test_results</span> <span class="o">-</span><span class="n">b</span> <span class="n">master</span> <span class="o">--</span><span class="n">hist</span><span class="o">-</span><span class="n">only</span> <span class="n">SMS</span><span class="o">.</span><span class="n">ne30_f19_g16_rx1</span><span class="o">.</span><span class="n">A</span>
</pre></div>
</div>
<p>The <cite>compare_test_results &lt;../Tools_user/compare_test_results.html&gt;_</cite> tool can be used to quickly compare tests to baselines and report any <cite>diffs</cite>.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">./</span><span class="n">CIME</span><span class="o">/</span><span class="n">Tools</span><span class="o">/</span><span class="n">compare_test_results</span> <span class="o">-</span><span class="n">b</span> <span class="n">master</span> <span class="n">SMS</span><span class="o">.</span><span class="n">ne30_f19_g16_rx1</span><span class="o">.</span><span class="n">A</span>
</pre></div>
</div>
</section>
<section id="performance-baselines">
<h3><span class="section-number">10.7.4. </span>Performance baselines<a class="headerlink" href="#performance-baselines" title="Link to this heading"></a></h3>
<p id="id10">By default performance baselines are generated by parsing the coupler log and comparing the throughput in SYPD (Simulated Years Per Day) and the memory usage high water.</p>
<p>This can be customized by creating a python module under <code class="docutils literal notranslate"><span class="pre">$DRIVER_ROOT/cime_config/customize</span></code>. There are four hooks that can be used to customize the generation and comparison.</p>
<ul class="simple">
<li><p>perf_get_throughput</p></li>
<li><p>perf_get_memory</p></li>
<li><p>perf_compare_throughput_baseline</p></li>
<li><p>perf_compare_memory_baseline</p></li>
</ul>
<p>The following pseudo code is an example of this customization.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># $DRIVER/cime_config/customize/perf_baseline.py</span>

<span class="k">def</span> <span class="nf">perf_get_throughput</span><span class="p">(</span><span class="n">case</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  case : CIME.case.case.Case</span>
<span class="sd">    Current case object.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  str</span>
<span class="sd">    Storing throughput value.</span>
<span class="sd">  str</span>
<span class="sd">    Open baseline file for writing.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">current</span> <span class="o">=</span> <span class="n">analyze_throughput</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">current</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span>

<span class="k">def</span> <span class="nf">perf_get_memory</span><span class="p">(</span><span class="n">case</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  case : CIME.case.case.Case</span>
<span class="sd">    Current case object.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  str</span>
<span class="sd">    Storing memory value.</span>
<span class="sd">  str</span>
<span class="sd">    Open baseline file for writing.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">current</span> <span class="o">=</span> <span class="n">analyze_memory</span><span class="p">(</span><span class="n">case</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">current</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span>

<span class="k">def</span> <span class="nf">perf_compare_throughput_baseline</span><span class="p">(</span><span class="n">case</span><span class="p">,</span> <span class="n">baseline</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  case : CIME.case.case.Case</span>
<span class="sd">    Current case object.</span>
<span class="sd">  baseline : str</span>
<span class="sd">    Baseline throughput value.</span>
<span class="sd">  tolerance : float</span>
<span class="sd">    Allowed difference tolerance.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  bool</span>
<span class="sd">    Whether throughput diff is below tolerance.</span>
<span class="sd">  str</span>
<span class="sd">    Comments about the results.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">current</span> <span class="o">=</span> <span class="n">analyze_throughput</span><span class="p">(</span><span class="n">case</span><span class="p">)</span>

  <span class="n">baseline</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">baseline</span><span class="p">)</span>

  <span class="n">diff</span><span class="p">,</span> <span class="n">comments</span> <span class="o">=</span> <span class="n">generate_diff</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">diff</span><span class="p">,</span> <span class="n">comments</span>

<span class="k">def</span> <span class="nf">perf_compare_memory_baseline</span><span class="p">(</span><span class="n">case</span><span class="p">,</span> <span class="n">baseline</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  case : CIME.case.case.Case</span>
<span class="sd">    Current case object.</span>
<span class="sd">  baseline : str</span>
<span class="sd">    Baseline memory value.</span>
<span class="sd">  tolerance : float</span>
<span class="sd">    Allowed difference tolerance.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  bool</span>
<span class="sd">    Whether memory diff is below tolerance.</span>
<span class="sd">  str</span>
<span class="sd">    Comments about the results.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">current</span> <span class="o">=</span> <span class="n">analyze_memory</span><span class="p">(</span><span class="n">case</span><span class="p">)</span>

  <span class="n">baseline</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">baseline</span><span class="p">)</span>

  <span class="n">diff</span><span class="p">,</span> <span class="n">comments</span> <span class="o">=</span> <span class="n">generate_diff</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">diff</span><span class="p">,</span> <span class="n">comments</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cime-customize.html" class="btn btn-neutral float-left" title="9. CIME config and hooks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="troubleshooting.html" class="btn btn-neutral float-right" title="11. Troubleshooting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, U.S. National Science Foundation and U.S. Department of Energy.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
     
<script>var version_json_loc = "../../../versions.json";</script>


</footer>
        </div>
      </div>
    </section>
  </div>
  

  <script type="text/javascript">
    let baseUriRegex = /(.*\/cime)\/.*/g;
    let parsedUri = baseUriRegex.exec(document.baseURI);

    if (parsedUri != null && parsedUri.length == 2) {
      let baseUri = parsedUri[1];

      $.get(`${baseUri}/versions/versions.json`, function(data) {
        let versionElement = $("#versions");

        Object.keys(data).forEach(function(key) {
          let value = data[key];

          let item = `<dd><a href="${baseUri}/versions/${key}/html/">${value}</a></dd>`

          versionElement.append(item);
        });
      });
    }
  </script>
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: master
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      
      <dl id="versions">
        <dt>Versions</dt>
      </dl>
      
      
    </div>
  </div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>